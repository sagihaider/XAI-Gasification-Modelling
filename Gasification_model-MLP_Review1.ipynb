{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean, std, absolute\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.preprocessing import normalize\n",
    "import time\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Data/Gasification Data.xlsx', index_col=0, header=0)\n",
    "data = data.iloc[1:223,:14] \n",
    "# display(list(data.columns.values))\n",
    "\n",
    "# Drop null balues and store dataframe in dataframe 2\n",
    "data=data.dropna()\n",
    "\n",
    "#Check Null values again after removing\n",
    "print(data.isnull().values.any())\n",
    "print(data.isna().values.any())\n",
    "\n",
    "X = data.iloc[:, :9]\n",
    "y = data.iloc[:, 9:]\n",
    "input_columns = list(X.columns.values)\n",
    "input_columns = [i.split(' [', 1)[0] for i in input_columns]\n",
    "output_columns = list(y.columns.values)\n",
    "output_columns = [i.split(' [', 1)[0] for i in output_columns]\n",
    "print(input_columns, output_columns)\n",
    "\n",
    "Xvals = X.values\n",
    "yvals = y.values\n",
    "print(Xvals.shape, yvals.shape)\n",
    "\n",
    "Xnorm = np.zeros_like(Xvals)\n",
    "ynorm = np.zeros_like(yvals)\n",
    "for idx in range(len(input_columns)):\n",
    "    Xnorm[:, idx] = (Xvals[:,idx]-min(Xvals[:,idx]))/(max(Xvals[:,idx])-min(Xvals[:,idx]))\n",
    "for odx in range(len(output_columns)):\n",
    "    ynorm[:, odx] = (yvals[:,odx]-min(yvals[:,odx]))/(max(yvals[:,odx])-min(yvals[:,odx]))\n",
    "\n",
    "print(np.max(Xnorm), np.max(ynorm))\n",
    "print(np.min(Xnorm), np.min(ynorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(Xnorm[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "methods = ['MLP']\n",
    "random_state = 42\n",
    "hidden_layers = [2, 4, 6, 8]\n",
    "activation = ['logistic', 'tanh', 'relu']\n",
    "alpha = [0.1, 0.01, 0.001, 0.0001]\n",
    "learning_rate = 'adaptive'\n",
    "learning_rate_init = [0.01, 0.001]\n",
    "early_stopping = True\n",
    "\n",
    "methods_extended = []\n",
    "for met in methods:\n",
    "    for hlayer in hidden_layers:\n",
    "        for act in activation:\n",
    "            for alp in alpha:\n",
    "                for lr_init in learning_rate_init:\n",
    "                    methods_extended.append(met + '_hlayer_' + str(hlayer) + '_act_' + str(act)+\n",
    "                                            '_alpha_' + str(alp) +'_lr_' + str(lr_init))\n",
    "print(methods_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xnorm, ynorm, test_size=.3, random_state=random_state)\n",
    "\n",
    "prediction = {}\n",
    "error = {}\n",
    "r2value = {}\n",
    "for met in methods_extended:\n",
    "    print(met)\n",
    "    score = {}\n",
    "    prediction[met] = np.zeros_like(y_test) \n",
    "    \n",
    "    string_extract = met.split('_')\n",
    "    \n",
    "    for idx in range(y.shape[1]):\n",
    "        start = time.time()\n",
    "        training_x = np.asarray(X_train)\n",
    "        testing_x = np.asarray(X_test)\n",
    "        training_y = np.asarray(y_train)[:, idx]\n",
    "        testing_y = np.asarray(y_test)[:, idx]\n",
    "        regr_multimlp = MLPRegressor(hidden_layer_sizes=int(string_extract[2]), activation=string_extract[4], \n",
    "                                     solver='adam', alpha=float(string_extract[6]), batch_size='auto', \n",
    "                                     learning_rate=learning_rate, learning_rate_init=float(string_extract[8]), \n",
    "                                     power_t=0.5, max_iter=1000, shuffle=True, random_state=random_state, \n",
    "                                     tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                                     nesterovs_momentum=True, early_stopping=early_stopping, \n",
    "                                     validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, \n",
    "                                     n_iter_no_change=10)\n",
    "        end = time.time()\n",
    "        print('Computational Time:', end-start)\n",
    "        regr_multimlp.fit(training_x, training_y)\n",
    "        prediction[met][:, idx] = regr_multimlp.predict(testing_x)\n",
    "    \n",
    "    error[met] = np.sqrt(mse(y_test, prediction[met], multioutput='raw_values'))\n",
    "    r2value[met] = r2(y_test, prediction[met], multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "mean_error = []\n",
    "mean_std = []\n",
    "mean_r2 = []\n",
    "for met in methods_extended:\n",
    "    mean_error.append(np.mean(error[met]))\n",
    "    mean_std.append(np.std(error[met]))\n",
    "    mean_r2.append(np.mean(r2value[met]))\n",
    "np.savetxt('mean_error_MLP.csv', mean_error)\n",
    "np.savetxt('mean_r2_MLP.csv', mean_r2)\n",
    "mim = np.argmin(mean_error)\n",
    "print(methods_extended[mim])\n",
    "mi2 = np.argmax(mean_r2)\n",
    "print(methods_extended[mi2])\n",
    "print(mim, mi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the RMSE and R-2 for the best MLP model\n",
    "rmse_best_index = np.argmin(mean_error)\n",
    "print(rmse_best_index)\n",
    "rmse_best = error[methods_extended[rmse_best_index]]\n",
    "print(rmse_best, np.mean(rmse_best))\n",
    "\n",
    "r2_best_index = np.argmax(mean_r2)\n",
    "print(r2_best_index)\n",
    "r2_best = r2value[methods_extended[r2_best_index]]\n",
    "print(r2_best, np.mean(r2_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Plot\n",
    "for met in methods_extended:\n",
    "    for odx, out in enumerate(output_columns):\n",
    "#         plt.subplot(5, 1, odx +1)\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(np.asarray(y_test)[:, odx], label='True value', color='blue')\n",
    "        plt.plot(np.asarray(prediction[met])[:, odx], color='red', \n",
    "                 label='Predicted value \\n (RMSE = %.4f \\n R2=%.3f)' % (error[met][odx], (r2value[met][odx])))\n",
    "        plt.xlabel(\"Features\", fontsize=12)\n",
    "        plt.ylabel(\"Values\", fontsize=12)\n",
    "        plt.rc('xtick',labelsize=12)\n",
    "        plt.rc('ytick',labelsize=12)\n",
    "        plt.title(\"%s (%s)\" % (met, out), fontsize=14)\n",
    "        plt.legend(fontsize=12)\n",
    "\n",
    "        plt.savefig('Results/Prediction_%s_%s.pdf' % (met, out))\n",
    "        plt.clf()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
