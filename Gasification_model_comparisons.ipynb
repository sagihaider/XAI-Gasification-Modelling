{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean, std, absolute\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LassoLarsIC, BayesianRidge, PoissonRegressor\n",
    "# import xgboost as xg\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Data/Gasification Data.xlsx', index_col=0, header=0)\n",
    "data = data.iloc[1:223,:14] \n",
    "# display(list(data.columns.values))\n",
    "\n",
    "# Drop null balues and store dataframe in dataframe 2\n",
    "data=data.dropna()\n",
    "\n",
    "#Check Null values again after removing\n",
    "print(data.isnull().values.any())\n",
    "print(data.isna().values.any())\n",
    "\n",
    "X = data.iloc[:, :9]\n",
    "y = data.iloc[:, 9:]\n",
    "input_columns = list(X.columns.values)\n",
    "input_columns = [i.split(' [', 1)[0] for i in input_columns]\n",
    "output_columns = list(y.columns.values)\n",
    "output_columns = [i.split(' [', 1)[0] for i in output_columns]\n",
    "print(input_columns, output_columns)\n",
    "\n",
    "Xvals = X.values\n",
    "yvals = y.values\n",
    "print(Xvals.shape, yvals.shape)\n",
    "\n",
    "Xnorm = np.zeros_like(Xvals)\n",
    "ynorm = np.zeros_like(yvals)\n",
    "for idx in range(len(input_columns)):\n",
    "    Xnorm[:, idx] = (Xvals[:,idx]-min(Xvals[:,idx]))/(max(Xvals[:,idx])-min(Xvals[:,idx]))\n",
    "for odx in range(len(output_columns)):\n",
    "    ynorm[:, odx] = (yvals[:,odx]-min(yvals[:,odx]))/(max(yvals[:,odx])-min(yvals[:,odx]))\n",
    "\n",
    "print(np.max(Xnorm), np.max(ynorm))\n",
    "print(np.min(Xnorm), np.min(ynorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(Xnorm[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "methods = ['Linear', 'Ridge', 'LARS', 'RF', 'Bag', 'GradientBoost']\n",
    "number_of_folds = 11\n",
    "ridge_reg = [1.0, 10.0, 100.0, 1000.0, 1e6]\n",
    "n_estimators = [10, 50, 100, 500, 1000]\n",
    "learning_rate = [1e-3, 0.01, 0.1, 1]\n",
    "max_depth = 30\n",
    "\n",
    "methods_extended = []\n",
    "for met in methods:\n",
    "    if met == 'Linear' or met == 'LARS':\n",
    "        methods_extended.append(met)\n",
    "    elif met == 'Ridge':\n",
    "        for reg in ridge_reg:\n",
    "            methods_extended.append(met + '_Reg_' + str(reg))\n",
    "    elif met == 'RF':\n",
    "        for rfest in n_estimators:\n",
    "            methods_extended.append(met + '_est_' + str(rfest))\n",
    "    elif met == 'Bag':\n",
    "        for best in n_estimators:\n",
    "            methods_extended.append(met + '_est_' + str(best))\n",
    "    elif met == 'GradientBoost':\n",
    "        for gbest in n_estimators:\n",
    "            for lr in learning_rate:\n",
    "                methods_extended.append(met + '_est_' + str(gbest) + \n",
    "                                        '_lr_' + str(lr))\n",
    "print(methods_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the data into 70% training set and 30% test set\n",
    "import time\n",
    "seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xnorm, ynorm, test_size=.3, random_state=seed)\n",
    "\n",
    "prediction = {}\n",
    "error = {}\n",
    "r2value = {}\n",
    "for met in methods_extended:\n",
    "    print(met)\n",
    "    score = {}\n",
    "    prediction[met] = np.zeros_like(y_test) \n",
    "    \n",
    "    string_extract = met.split('_')\n",
    "    \n",
    "    for idx in range(y.shape[1]):\n",
    "        training_x = np.asarray(X_train)\n",
    "        testing_x = np.asarray(X_test)\n",
    "        training_y = np.asarray(y_train)[:, idx]\n",
    "        testing_y = np.asarray(y_test)[:, idx]\n",
    "\n",
    "        if string_extract[0] == 'Linear':\n",
    "            start_linear = time.time()\n",
    "            regr_multilin = LinearRegression()\n",
    "            regr_multilin.fit(training_x, training_y)\n",
    "            prediction[met][:, idx] = regr_multilin.predict(testing_x)\n",
    "            end_linear = time.time()\n",
    "            print('CT-Linear', end_linear-start_linear)\n",
    "\n",
    "        elif string_extract[0] == 'Ridge':\n",
    "            start_ridge = time.time()\n",
    "            regr_multiridge = Ridge(alpha=float(string_extract[-1]))\n",
    "            regr_multiridge.fit(training_x, training_y)\n",
    "            prediction[met][:, idx] = regr_multiridge.predict(testing_x)\n",
    "            end_ridge = time.time()\n",
    "            print('CT-ridge', end_ridge-start_ridge)\n",
    "\n",
    "        elif string_extract[0] == 'LARS':\n",
    "            start_lars = time.time()\n",
    "            regr_multilasso = LassoLarsIC()\n",
    "            regr_multilasso.fit(training_x, training_y)\n",
    "            prediction[met][:, idx] = regr_multilasso.predict(testing_x)\n",
    "            end_lars = time.time()\n",
    "            print('CT-lars', end_lars-start_lars)\n",
    "\n",
    "        elif string_extract[0] == 'RF':\n",
    "            start_rf = time.time()\n",
    "            regr_multirf = RandomForestRegressor(n_estimators=int(string_extract[-1]),\n",
    "                                                                  max_depth=max_depth,\n",
    "                                                                  random_state=0)\n",
    "            regr_multirf.fit(training_x, training_y)\n",
    "            prediction[met][:, idx] = regr_multirf.predict(testing_x)\n",
    "            end_rf = time.time()\n",
    "            print('CT-rf', end_rf-start_rf)\n",
    "\n",
    "        elif string_extract[0] == 'Bag':\n",
    "            start_bag = time.time()\n",
    "            regr_multibag = BaggingRegressor(n_estimators=int(string_extract[-1]),\n",
    "                                                                  random_state=0)\n",
    "            regr_multibag.fit(training_x, training_y)\n",
    "            prediction[met][:, idx] = regr_multibag.predict(testing_x)\n",
    "            end_bag = time.time()\n",
    "            print('CT-bag', end_bag-start_bag)\n",
    "\n",
    "        elif string_extract[0] == 'GradientBoost':\n",
    "            start_gb = time.time()\n",
    "            regr_multigb = GradientBoostingRegressor(n_estimators=int(string_extract[-3]), \n",
    "                                                                          learning_rate=float(string_extract[-1]),\n",
    "                                                                          random_state=seed, loss='huber')\n",
    "            regr_multigb.fit(training_x, training_y)\n",
    "            prediction[met][:, idx] = regr_multigb.predict(testing_x)\n",
    "            end_gb = time.time()\n",
    "            print('CT-gb', end_gb-start_gb)   \n",
    "    error[met] = np.sqrt(mse(y_test, prediction[met], multioutput='raw_values'))\n",
    "    r2value[met] = r2(y_test, prediction[met], multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "mean_error = []\n",
    "mean_std = []\n",
    "mean_r2 = []\n",
    "for met in methods_extended:\n",
    "    mean_error.append(np.mean(error[met]))\n",
    "    mean_std.append(np.std(error[met]))\n",
    "    mean_r2.append(np.mean(r2value[met]))\n",
    "## Identifying the best model\n",
    "np.savetxt('mean_error.csv', mean_error)\n",
    "np.savetxt('mean_r2.csv', mean_r2)\n",
    "mim = np.argmin(mean_error)\n",
    "print(methods_extended[mim])\n",
    "mi2 = np.argmax(mean_r2)\n",
    "print(methods_extended[mi2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Plot\n",
    "for met in methods_extended:\n",
    "    for odx, out in enumerate(output_columns):\n",
    "#         plt.subplot(5, 1, odx +1)\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(np.asarray(y_test)[:, odx], label='True value', color='blue')\n",
    "        plt.plot(np.asarray(prediction[met])[:, odx], color='red', \n",
    "                 label='Predicted value \\n (RMSE = %.4f \\n R2=%.3f)' % (error[met][odx], (r2value[met][odx])))\n",
    "        plt.xlabel(\"Features\", fontsize=12)\n",
    "        plt.ylabel(\"Values\", fontsize=12)\n",
    "        plt.rc('xtick',labelsize=12)\n",
    "        plt.rc('ytick',labelsize=12)\n",
    "        plt.title(\"%s (%s)\" % (met, out), fontsize=14)\n",
    "        plt.legend(fontsize=12)\n",
    "\n",
    "        plt.savefig('Results/Prediction_%s_%s.pdf' % (met, out))\n",
    "        plt.clf()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
